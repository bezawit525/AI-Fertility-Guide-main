# üß† Efoyta Therapy ‚Äî AI-Powered Mental Health Guide

> An intelligent, AI-assisted mental health therapy platform that delivers personalized advice, empathetic conversations, and voice-enabled interactions ‚Äî built with **Streamlit** and **OpenAI GPT-4**.

---

## üìã Table of Contents

- [Overview](#-overview)
- [Features](#-features)
- [Tech Stack](#-tech-stack)
- [Project Structure](#-project-structure)
- [Prerequisites](#-prerequisites)
- [Installation](#-installation)
- [Usage](#-usage)
- [Configuration](#-configuration)
- [Application Workflow](#-application-workflow)
- [Module Documentation](#-module-documentation)
- [Contributing](#-contributing)
- [License](#-license)
- [Developer](#-developer)

---

## üåü Overview

**Efoyta Therapy** is a web-based mental health support application that combines the power of OpenAI's GPT-4 language model with an intuitive Streamlit interface. The platform guides users through a personalized questionnaire to understand their mental health needs, then provides AI-generated therapeutic advice, real-time chat support, and text-to-speech audio responses.

The application is designed to offer:

- **Empathetic, AI-driven support** tailored to individual user profiles
- **Voice input/output** capabilities for accessible, hands-free interaction
- **Privacy-first design** with explicit user consent before data processing
- **Personalized recommendations** based on age, gender, health status, and user-described concerns

---

## ‚ú® Features

| Feature                          | Description                                                                 |
| -------------------------------- | --------------------------------------------------------------------------- |
| üè† **Welcome Dashboard**        | Informational landing page with cards highlighting key services             |
| üìù **Multi-Step Questionnaire** | Guided profile builder collecting personal info, health status, and needs   |
| üé§ **Voice Input (STT)**        | Record audio to describe symptoms ‚Äî transcribed via OpenAI Whisper          |
| üí¨ **AI Chat Assistant**        | Real-time conversational chatbot powered by GPT-4 Turbo                    |
| üîä **Text-to-Speech (TTS)**     | AI responses are automatically converted to audio using OpenAI TTS          |
| üó∫Ô∏è **Clinic Finder**           | Interactive PyDeck map displaying nearby mental health clinics              |
| üîí **Privacy & Consent**        | Explicit consent collection before any data is used for personalization     |
| üìä **Feedback System**          | In-app feedback collection to continuously improve advice quality           |

---

## üõ†Ô∏è Tech Stack

| Technology              | Purpose                                      |
| ----------------------- | -------------------------------------------- |
| **Python 3.8+**         | Core programming language                    |
| **Streamlit**           | Web application framework & UI               |
| **OpenAI API (GPT-4)**  | AI-powered chat, advice generation           |
| **OpenAI Whisper**      | Speech-to-text transcription                 |
| **OpenAI TTS**          | Text-to-speech audio generation              |
| **Streamlit Card**      | Custom card UI components                    |
| **Streamlit AudioRec**  | In-browser audio recording                   |
| **Pandas**              | Data manipulation for clinic data            |
| **PyDeck**              | Interactive 3D map visualization             |

---

## üìÅ Project Structure

```
AI-Mental-Health-Guide-App/
‚îÇ
‚îú‚îÄ‚îÄ app.py              # Main application entry point & page routing
‚îú‚îÄ‚îÄ assistant.py        # OpenAI API integration (chat, TTS, STT)
‚îú‚îÄ‚îÄ questions.py        # Multi-step questionnaire & user data collection
‚îú‚îÄ‚îÄ response.py         # Personalized advice display & chat interface
‚îú‚îÄ‚îÄ clinics.py          # Clinic finder with interactive map
‚îú‚îÄ‚îÄ figma.py            # UI prototype components & card layouts
‚îú‚îÄ‚îÄ style.css           # Custom CSS for sidebar button styling
‚îú‚îÄ‚îÄ requirements.txt    # Python dependencies
‚îú‚îÄ‚îÄ audio.mp3           # Generated TTS audio output file
‚îÇ
‚îî‚îÄ‚îÄ asset/              # Static assets
    ‚îú‚îÄ‚îÄ petal_cover.png      # Welcome page cover image
    ‚îú‚îÄ‚îÄ petal-logo-w.png     # Sidebar logo (white variant)
    ‚îú‚îÄ‚îÄ petal-logo.png       # Standard logo
    ‚îú‚îÄ‚îÄ mental.png           # Mental health icon
    ‚îî‚îÄ‚îÄ Inclusive SH.jpeg    # Inclusive health imagery
```

---

## üìå Prerequisites

Before running the application, ensure you have:

1. **Python 3.8 or higher** installed on your system
2. An **OpenAI API key** with access to:
   - GPT-4 Turbo (chat completions)
   - Whisper (audio transcription)
   - TTS (text-to-speech)
3. **pip** (Python package manager)

---

## üöÄ Installation

### 1. Clone the Repository

```bash
git clone https://github.com/your-username/AI-Mental-Health-Guide-App.git
cd AI-Mental-Health-Guide-App
```

### 2. Create a Virtual Environment (Recommended)

```bash
# Windows
python -m venv venv
venv\Scripts\activate

# macOS / Linux
python3 -m venv venv
source venv/bin/activate
```

### 3. Install Dependencies

```bash
pip install -r requirements.txt
```

The `requirements.txt` includes:

```
openai>=1.2
streamlit-feedback
streamlit-extras
streamlit-card
streamlit-audiorec
pandas
pydeck
```

> **Note:** `streamlit` is installed automatically as a dependency of the Streamlit extension packages.

---

## ‚ñ∂Ô∏è Usage

### Run the Application

```bash
streamlit run app.py
```

The app will launch in your default browser at `http://localhost:8501`.

### Enter Your API Key

1. In the sidebar, paste your **OpenAI API key** into the input field
2. If you don't have one, click the provided link: [Get an OpenAI API Key](https://platform.openai.com/account/api-keys)

---

## ‚öôÔ∏è Configuration

| Setting           | Location       | Description                                      |
| ----------------- | -------------- | ------------------------------------------------ |
| Page Title        | `app.py`       | Set to `"Efoyta Therapy"` via `st.set_page_config()` |
| OpenAI Model      | `assistant.py` | Uses `gpt-4-turbo` for chat and `gpt-4o-mini` for assistants |
| TTS Voice         | `response.py`  | Set to `"nova"` ‚Äî can be changed to `alloy`, `echo`, `fable`, `onyx`, or `shimmer` |
| Whisper Model     | `assistant.py` | Uses `whisper-1` for speech-to-text              |
| Layout            | `app.py`       | Wide layout enabled via `layout="wide"`          |

---

## üîÑ Application Workflow

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Welcome Page   ‚îÇ  ‚Üê Landing page with service overview cards
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ "Get Started"
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Questionnaire   ‚îÇ  ‚Üê Multi-step form (5 pages):
‚îÇ                  ‚îÇ     1. Voice/text needs description
‚îÇ                  ‚îÇ     2. Personal info (age, gender)
‚îÇ                  ‚îÇ     3. Health status & symptoms
‚îÇ                  ‚îÇ     4. Additional lifestyle info
‚îÇ                  ‚îÇ     5. Privacy consent
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ "Finish" (with consent)
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Personalized AI  ‚îÇ  ‚Üê GPT-4 generates tailored advice
‚îÇ   Advice Chat    ‚îÇ  ‚Üê Response is read aloud via TTS
‚îÇ                  ‚îÇ  ‚Üê Ongoing chat for follow-up questions
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üìñ Module Documentation

### `app.py` ‚Äî Main Application

The entry point of the application. Handles:

- **Page configuration** ‚Äî Sets the page title, icon, layout, and meta info
- **Sidebar navigation** ‚Äî Renders navigation buttons (Home, Profile, Personalized Advice, Help) and the API key input
- **Page routing** ‚Äî Uses `st.session_state['current_page']` to route between `welcome`, `questions`, `chat`, and `clinics` views
- **Welcome page** ‚Äî Displays a cover image and three informational cards (Mental Health Education, Shared Decision-Making, Personalized Recommendations)

### `assistant.py` ‚Äî OpenAI Integration (`PetalAssitant` class)

Core AI functionality wrapper around the OpenAI API:

- **`create_openai_assistant_prompt(user_data)`** ‚Äî Constructs a detailed prompt from the user's profile data (age, gender, health status, description)
- **`generate_response(user_data, api_key)`** ‚Äî Sends the constructed prompt to GPT-4 Turbo and returns personalized mental health advice
- **`chat(messages)`** ‚Äî Handles multi-turn conversation by passing the full message history to the model
- **`text_to_speech(text, voice)`** ‚Äî Converts text to speech using OpenAI's TTS-1 model and saves to `audio.mp3`
- **`transcribe(audio_path)`** ‚Äî Transcribes audio recordings to text using OpenAI Whisper

### `questions.py` ‚Äî Questionnaire System

A multi-page questionnaire flow with progress tracking:

- **`collect_user_needs()`** ‚Äî Audio recording for the user to describe their needs, with Whisper-based transcription
- **`collect_personal_info()`** ‚Äî Collects age and gender identity
- **`collect_health_status()`** ‚Äî Captures overall health rating and symptom descriptions
- **`collect_other_info()`** ‚Äî Free-text input for lifestyle, mental health, and economic factors
- **`privacy_concent()`** ‚Äî Collects explicit user consent before processing data
- **`compile_user_data()`** ‚Äî Aggregates all session state data into a structured dictionary for AI processing
- **`navigate()`** ‚Äî Handles page-to-page navigation with Back/Next buttons

### `response.py` ‚Äî Personalized Advice & Chat

Manages the AI response display and interactive chat:

- **`display_response()`** ‚Äî Generates personalized advice using the user's profile, plays it as audio, and initiates an ongoing chat session
- **`autoplay_audio(file_path)`** ‚Äî Embeds and auto-plays the generated MP3 audio in the browser
- **`save_feedback(user_data, feedback)`** ‚Äî Placeholder for persisting user feedback (extensible to database integration)

### `clinics.py` ‚Äî Clinic Finder

Interactive map-based clinic locator:

- Displays nearby clinics on a **PyDeck** interactive map with labeled markers
- Shows clinic names, coordinates, and services offered via tooltips
- Currently uses sample clinic data (extensible to live API integration)

### `figma.py` ‚Äî UI Prototype Components

Contains alternative UI layout prototypes:

- **`figma_welcome()`** ‚Äî An alternate welcome page layout with a "MOJO Plan" theme
- **`figma_profile()`** ‚Äî A stepped card-based profile builder UI with audio recording support
- **`create_card()`** ‚Äî Reusable card component with custom styling (shadows, borders, rounded corners)

---

## ü§ù Contributing

Contributions are welcome! To contribute:

1. **Fork** the repository
2. **Create** a feature branch: `git checkout -b feature/your-feature-name`
3. **Commit** your changes: `git commit -m "Add your feature"`
4. **Push** to the branch: `git push origin feature/your-feature-name`
5. **Open** a Pull Request

### Development Guidelines

- Follow **PEP 8** coding standards for Python
- Add docstrings to all new functions and classes
- Test your changes locally with `streamlit run app.py` before submitting
- Update this README if you add new features or modify the project structure

---

## üìÑ License

This project is open-source and available under the [MIT License](LICENSE).

---

## üë©‚Äçüíª Developer

**Bezawit Hayle**

---

> *Built with ‚ù§Ô∏è using Streamlit & OpenAI ‚Äî empowering mental health support through AI.*
